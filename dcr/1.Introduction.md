# Chapter 1. Introduction

## 动机 Motivation

Paxos算法中的每个决定达成一致都依赖集群的简单多数majority节点，从而Paxos算法集群的网络负载以及**leader/distinguished proposer节点负载会相当高**，因此**往往规模被限制在3/5个节点**

由于Paxos依赖简单多数，因此**当过半节点失效时，Paxos集群就无法继续提供共识服务**，失效的可能原因包括网络分区network partitions、慢节点slow hosts、网络堵塞network congestion、资源竞争contention for resources、时钟偏移clock skew、丢包packet loss等

那么这些局限是源自分布式共识，还是源自Paxos算法本身？

## 局限 Scope & Limitations

- **Byzantine fault tolerance**：假定没有拜占庭故障，即所有节点可靠、正确的运行算法，没有恶意节点，只存在异步网络的丢包、乱序、延迟问题
- **Reconfiguration**：假定集群是固定的，每个成员节点都有一个UID，成员变更算法在Stoppable Paxos、VRR、[Raft](https://github.com/JasonYuchen/notes/blob/master/raft/04.Cluster_Membership_Change.md#chapter-4-cluster-membership-changes)中有大量讨论
- **Weakened semantics**：不讨论弱化语义的操作，例如[直接读取可能过期的数据stale read、依赖本地时终的读取leader lease](https://github.com/JasonYuchen/notes/blob/master/raft/06.Client_Interaction.md#%E6%9B%B4%E6%9C%89%E6%95%88%E7%9A%84%E5%A4%84%E7%90%86%E5%8F%AA%E8%AF%BB%E8%AF%B7%E6%B1%82-processing-read-only-queries-more-efficiently)
- **Implementation details**：假定存储空间无限、所有数据不会损坏、所有节点状态不会损坏，节点可以停机及重启，重启后状态能恢复到停机前，在本thesis中展示的算法及伪代码是单线程顺序执行并且每一行都是原子的的，从存储中读取数据一定是最新的值
- **Partial ordering**：算法用于确定单个值（或一个全序无限数量的值totally ordered, infinite sequence of values），不考虑多个序列multiple series of values的共识，也不考虑偏序partially ordered sequences或有限序列finite sequences
- **Progress in practice**：所有节点可以以任意速度运行，消息可以经过任意延时后抵达，同时消息也可以乱序、重复（丢失后重复发送）
- **Specific systems**：所有算法不依赖具体的硬件、网络等假设，也不对工作负载有任何假设，例如Ring Paxos/Multi-Ring Paxos就对支持IP多播的网络有优化
