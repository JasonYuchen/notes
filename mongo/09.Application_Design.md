# Chapter 09 Application Design

## Schema Design Considerations

### Key Aspects to Consider

- **Constraints**

    database or hardware limitations, e.g. the maximum doc size of 16 MB

- **Access patterns**

    when queries are running and how frequently, identify the most common ones
    
    - **data locality**, store related data in the same doc
    - **hot/cold data separation**, data that is infrequently used should be moved to a different collection
    - **dynamic/static separation**, read/write data and mostly read data may be stored separately

- **Relation types**

    **embed or reference**, how many docs are updated when there is a relationship change

- **Cardinality**

    the cardinality of the relationships, 1-to-1, 1-to-many, many-to-many, 1-to-millions, many-to-millions?

### Schema Design Patterns

- **Polymorphic pattern** [example](https://www.mongodb.com/developer/products/mongodb/polymorphic-pattern/)

    when all docs in a collection have a **similar but not identical structure**

    identify the **common fields that support the common queries**, track specific fields

- **Attribute pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-attribute-pattern)

    when there are **a subset of fields** in a doc that share common features you want to **sort on or query**, or when the fields you want to sort on only exists in **a subset of the docs**

    reshape the data into **an array of key/value pairs** and create an **index** on the elements in this array, target many similar fields per doc to reduce the indexes

    ```
    {
        title: "Star Wars",
        director: "George Lucas",
        ...
        release_US: ISODate("1977-05-20T01:00:00+01:00"),
        release_France: ISODate("1977-10-19T01:00:00+01:00"),
        release_Italy: ISODate("1977-10-20T01:00:00+01:00"),
        release_UK: ISODate("1977-12-27T01:00:00+01:00"),
        ...
    }
    
    // many indexes
    {release_US: 1}
    {release_France: 1}
    {release_Italy: 1}
    ...
    ```

    ```
    {
        title: "Star Wars",
        director: "George Lucas",
        …
        releases: [
            {
            location: "USA",
            date: ISODate("1977-05-20T01:00:00+01:00")
            },
            {
            location: "France",
            date: ISODate("1977-10-19T01:00:00+01:00")
            },
            {
            location: "Italy",
            date: ISODate("1977-10-20T01:00:00+01:00")
            },
            {
            location: "UK",
            date: ISODate("1977-12-27T01:00:00+01:00")
            },
            … 
        ],
        … 
    }
    
    // one index
    { "releases.location": 1, "releases.date": 1}
    ```

- **Bucket pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-bucket-pattern)

    when data is **time series** and is captured as a stream over a period of time

    e.g. use a one-hour bucket to store all readings for that hour in a single document, **one document per bucket with start/end time**

- **Outlier pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-outlier-pattern)

    when a few queries of docs **fall outside the normal pattern** for the application, e.g. social networks with major influencers, book sales, movie reviews, etc

    use a flag to indicate the doc is an outlier and **store the additional overflow into other docs that refer back to the first doc** via `_id`

- **Computed pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-computed-pattern)

    when data needs to be **computed frequently** or data access pattern is **read-intensive**

    carry out the **calculation in the background** with the **main doc being updated periodically**

- **Subset pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-subset-pattern)

    when the working set exceeds the available RAM by large docs that contains **a lot of data that is used infrequently**

    **split** frequently used data and infrequently used data into two separate collections, e.g. store 10 most recent reviews of a product in the "main" collection and move all the older reviews into a secondary collection

- **Extended Reference pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-extended-reference-pattern)

    when want to gather **different logical entities together** for a specific function

    identify the frequently accessed fields and duplicate these within the doc, **trades off the duplication of data for a reduction in the number of queries**

- **Approximation pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-approximation-pattern)

    when resource-expensive **calculations** are needed **without exact precision**

- **Tree pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-tree-pattern)

    when have a lot of queries and have data that is primarily **hierarchical** in structure

    **store a hierarchy in an array** within the same document

    ```
    {
        employee_id: 5,
        name: "Jim",
        reports_to: [
            "Scott",
            "Leviton",
            "Wallace"
        ]
    }
    ```

- **Preallocation pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-preallocation-pattern)

    mainly used with the MMAP storage engine

- **Document Versioning pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-document-versioning-pattern)

    when need to enable **retention of older revisions** of documents

    maintain two collections, **one for current version, the other for older versions**

- **Schema Versioning pattern** [example](https://www.mongodb.com/blog/post/building-with-patterns-the-schema-versioning-pattern)

    when the **schema eventually needs to be altered**

    save a `schema_version` field in the doc, then applications can recognize/handle docs with the help of `schema_version`

## Normalization vs. Denormalization

Typically, **normalizing makes writes faster** and **denormalizing makes reads faster**. Consider how often this information will **change**, versus how often it’s **read**.

| Embeddeing is better for                  | References are better for                 |
| :---------------------------------------- | ----------------------------------------- |
| **small** sub-documents                   | **large** sub-documents                   |
| data that **does not change** regularly   | **volatile** data                         |
| **eventual consistency** is acceptable    | **immediate consistency** is necessary    |
| documents that grow by a **small amount** | documents that grow by a **large amount** |
| **Fast reads**                            | **Fast writes**                           |
| **few** relationships                     | **many** relationships                    |

**Cardinality** is an indication of how many references a collection has to another collection. Generally, **"few" relationships** will work better with embedding, and **"many" relationships** will work better as references.

e.g. students and classes

- normalization
    - `students` collection
    - `classes` collection
    - `studentClasses` collection

    ```
    > db.studentClasses.findOne({"studentId" : id})
    {
        "_id" : ObjectId("512512c1d86041c7dca81915"),
        "studentId" : ObjectId("512512a5d86041c7dca81914"),
        "classes" : [
            ObjectId("512512ced86041c7dca81916"),
            ObjectId("512512dcd86041c7dca81917"),
            ObjectId("512512e6d86041c7dca81918"),
            ObjectId("512512f0d86041c7dca81919")
        ]
    }
    ```

- denormalization v1
    - `students` collection with class references embedded
    - `classes` collection

    ```
    {
        "_id" : ObjectId("512512a5d86041c7dca81914"),
        "name" : "John Doe",
        "classes" : [
            ObjectId("512512ced86041c7dca81916"),
            ObjectId("512512dcd86041c7dca81917"),
            ObjectId("512512e6d86041c7dca81918"),
            ObjectId("512512f0d86041c7dca81919")
        ]
    }
    ```

- denormalization v2
    - `students` collection with class embedded
    - `classes` collection

    ```
    {
        "_id" : ObjectId("512512a5d86041c7dca81914"),
        "name" : "John Doe",
        "classes" : [
            {
                "class" : "Trigonometry",
                "credits" : 3,
                "room" : "204"
            },
            {
                "class" : "Physics",
                "credits" : 3,
                "room" : "159"
            }
        ]
    }
    ```

- **Extended Reference**, hybrid of embedding and referencing
    - `students` collection with **frequently used information** and **reference** embedded
    - `classes` collection

    ```
    {
        "_id" : ObjectId("512512a5d86041c7dca81914"),
        "name" : "John Doe",
        "classes" : [
            {
                "_id" : ObjectId("512512ced86041c7dca81916"),
                "class" : "Trigonometry"
            },
            {
                "_id" : ObjectId("512512dcd86041c7dca81917"),
                "class" : "Physics"
            }
        ]
    }
    ```

## Optimizations for Data Manipulation

- **Evaluating read/write performance**: identify bottleneck
- **Optimizing reads**: correct indexes, **returning** as much as possible **in a single document**
- **Optimizing writes**: minimized indexes, efficient updates
- **Removing old data**
    - **capped collection**: vulnerable to spikes in traffic
    - **TTL collections**: finer-grain control but may not be fast enough if write volume is high
    - **multiple collections**: e.g. one collection per month, more complex to build an application around

## Planning Out Databases and Collections

In general, documents with a **similar schema** should be kept in the **same collection**. Using **multiple physical volumes** to reduce I/O bottlenecks for different workloads.

e.g. SSD for users, RAID0 for logs and activities

## Managing Consistency

- A single connection (**per-connection request queue**) has a consistent view of the database, **Read-Your-Own-Write consistency**, be aware of **connection pooling** in MongoDB drivers
- **secondaries** may lag behind the primary, leading to **stale reads**
- `readConcern` and `writeConcern` to control the consistency and availability guarantees ([Tunable Consistency in MongoDB](https://www.vldb.org/pvldb/vol12/p2071-schultz.pdf))
    - `local`
    - `available`
    - `majority`
    - `linearizable`
    - `snapshot`

## Migrating Schemas

- **Document Versioning pattern**
- **Schema Versioning pattern**
- **Migrate all of the data when schema changes** (not recommended)

## Managing Schemas

**Schema validation** during updates and insertions via `$jsonSchema`

## When Not to Use MongoDB

**Joining** many different types of data across many different dimensions (choose **RDBMS**)
