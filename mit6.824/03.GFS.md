# Lecture 3. The Google File System

阅读材料笔记[GFS notes](GFS.md)

## 分布式存储的难点 Why is distributed storage hard?

1. 高性能 high performance -> 数据分片 shard data over many servers
1. 多服务器 many servers -> 故障 constant faults
1. 容错 fault tolerance -> 副本 replication
1. 副本 replication -> 不一致 potential inconsistencies
1. 更强的一致性 better consistency -> 低性能 low performance

## 不良的副本设计 simple but broken replication scheme

```text
    suppose C1 and C2 write concurrently, and after the writes have
      completed, C3 and C4 read. what can they see?
    C1: Wx1
    C2: Wx2
    C3:     Rx?
    C4:         Rx?
    answer: either 1 or 2, but both have to see the same value.
```

现在有两台互为备份的服务器S1, S2，所有clients均会写入S1和S2（双写double write），所有clients任意读取S1或S2，这种副本设计会导致：

- C1的Wx1和C2的Wx2到达S1和S2的顺序不一定一致，从而可能C3读出Wx1而C4读出Wx2，不一致
- S1收到了C1的Wx1，C1还未写入S2即宕机，不一致

**更强的一致性保证通常需要向所有服务器沟通以确保所有replicas同步，性能低下**

## GFS的架构与Read/Write流程

见[GFS notes](GFS.md)

```text
C: Client
M: Master
P: Primary

read a file
  1. C sends filename and offset to master M (if not cached)
  2. M finds chunk handle for that offset
  3. M replies with list of chunkservers
     only those with latest version
  4. C caches handle + chunkserver list
  5. C sends request to nearest chunkserver
     chunk handle, offset
  6. chunk server reads from chunk file on disk, returns

append record
  1. C asks M about file's last chunk
  2. if M sees chunk has no primary (or lease expired):
     2a. if no chunkservers w/ latest version #, error
     2b. pick primary P and secondaries from those w/ latest version #
     2c. increment version #, write to log on disk
     2d. tell P and secondaries who they are, and new version #
     2e. replicas write new version # to disk
  3. M tells C the primary and secondaries
  4. C sends data to all (just temporary...), waits
  5. C tells P to append
  6. P checks that lease hasn't expired, and chunk has space
  7. P picks an offset (at end of chunk)
  8. P writes chunk file (a Linux file)
  9. P tells each secondary the offset, tells to append to chunk file
  10. P waits for all secondaries to reply, or timeout
      secondary can reply "error" e.g. out of disk space
  11. P tells C "ok" or "error"
  12. C retries from start if error
```

**写入时可能出现partial failure**，例如部分secondary写入B失败，此时client和primary会尽可能重试，但当最终失败而另外的C却写入成功时，replicas就出现了不一致，应用程序此时可以参考[此](GFS.md#2.-对应用程序的含义-Implications-for-Applications)，而在GFS的层面上可以通过例如2PC等方式强化一致性（性能也会劣化）

```text
replica 1         2         3
head
     +-----+   +-----+   +-----+
     |  A  |   |  A  |   |  A  |  succeeded
     +-----+   +-----+   +-----+
     |  B  |   |  B  |   |  ?  |  failed
     +-----+   +-----+   +-----+
     |  C  |   |  C  |   |  C  |  succeeded
     +-----+   +-----+   +-----+
tail
```

当某个replica出现持续失败时，master应该能够检测到，并且移除该chunkserver，将影响到的replicas re-replication到其他chunkserver

## GFS的优点与局限

**优点：**

- 分布式文件系统
- 元数据naming master和数据storage chunkserver存储分离
- 数据分片sharding for parallel throughput
- 大文件和块文件减小额外开销huge files/chunks to reduce overheads
- 更好支持顺序写入primary to sequence writes
- 租约避免脑裂leases to prevent split-brain chunkserver primaries

**局限：**

- 单主节点性能瓶颈single master performance
- 不利于小文件处理chunkservers not very efficient for small files
- 主节点缺乏自动容错lack of automatic fail-over to master replica
- 过于弱的一致性保证maybe consistency was too relaxed
