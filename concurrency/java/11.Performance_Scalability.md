# Chapter 11. Performance and Scalability

## 1. Thinking about Performance

- 性能与可扩展性Performance Versus Scalability
- 评估性能Evaluating Performance Tradeoffs
  - **避免过早优化premature optimization**，首先做对，其次在不够快的时候再考虑优化
  - **Profiling而不是猜测性能瓶颈**

## 2. Amdahl's Law

```math
Speedup \leq \frac{1}{F + \frac{1-F}{N}}
```

## 3. Costs Introduced by Threads

- **上下文切换Context Switching**
- **内存同步Memory Synchronization**
  注意：在一些情况下，**无锁算法可能比有锁算法性能更差**，因为前者要求更多的内存同步开销
- **阻塞Blocking**

## 4. Reducing Lock Contention

锁竞争越激烈，程序的可扩展性越差，因为更多的线程加入了竞争，通过以下方法来减少竞争

- **减少同步区Narrowing Lock Scope**
- **减小锁的粒度Reducing Lock Granularity**
- **分段锁Lock Striping**
- **避免热点区域Avoiding Hot Fields**
  例如`ConcurrentHashMap`的size是各个segment分别维护自己的size，全局size是各个size的和，而各个size只有在增减元素需要同步的一个值，而非通过每次都遍历统计所有值来计算，由此分散了各个热点同时减小了同步区
- 其他方法
  - **并发容器concurrent collections**
  - **读写锁read-write locks**
  - **不可变对象immutable objects**
  - **原子变量atomic variables**
  - **乐观锁optimistic locks**
- **观测CPU使用率Monitoring CPU Utilization**
  `vmstat`/`mpstat`来观测CPU占用情况
  - **非均匀占用**：程序需要进一步挖掘并行计算的空间
  - **均匀占用但使用率不高**：
    - 负载较轻
    - I/O是瓶颈：`iostat`来观测IO占用情况
    - 外界原因如数据库缓慢等
    - 锁竞争
- **拒绝对象池化Just Say No to Object Pooling**
  早期由于JVM分配新对象慢而出现了对象池，对象复用（同时引入了锁），但是现代JVM对象分配速度比C还要快

## 5. Example: Comparing Map Performance

`TODO`

## 6. Reducing Context Switch Overhead

例如Logging全部转移到单个线程执行，避免了工作线程由于IO导致等待、上下文切换、锁竞争等问题，参考Seastar库的[Thread Per Core, TPC设计](https://github.com/JasonYuchen/notes/blob/master/seastar/Shared_Nothing.md)
