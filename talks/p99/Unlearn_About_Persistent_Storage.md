# What We Need to Unlearn about Persistent Storage

## HDD vs. SSD

- **面向HDD是困难的**
  1. HDD有物理移动的组件：转盘、磁头，导致寻址时间可以达到毫秒级，而任意一次IO都可能引起寻址
  2. 在HDD上高效的方式就是尽可能不触发寻址：连续读写
  3. 一种广泛使用的策略就是为了针对HDD进行优化：数据库的提交日志`commitlog`
- **SDD的特点**
  1. 类似RAM的存储结构，每个IO耗时可预测较稳定（没有HDD寻址的问题）
  2. 采用4个维度来描述性能，读/写的带宽MB/s，读/写的延迟IOPS op/s

## Overwriting

由于SSD内部的机制导致其有一些使用的限制：

- 读写必须以**页page**为最小单位，通常4K/page
- 擦除必须以**块block**为最小单位，通常128pages/block
- 不能原地更新update，只能先擦除数据随后再写入数据
- **磁盘控制器**内部会维护一个映射表来进行I/O偏移量到磁盘内偏移量的映射，并在后台通过页平衡算法来维护所有数据块的负载均衡，这些机制也有额外开销
- 磁盘老化后由于内部映射表的数据碎片化，**逻辑上的连续IO时实际落到SSD上的物理IO依然是随机的**，并且对该映射表的GC也会时不时影响系统的吞吐量

考虑到上述场景后的推荐做法：

- 依然还是推荐采用**顺序IO并且采用较大的缓存**
- 通过`trim`命令向SSD控制器**显式声明不再需要的数据块**，从而减轻SSD控制器的压力，文件系统可能也会采用这一点

## Burst vs. Sustain

- 数据实际写入闪存块前会**首先写入缓存**中，读取时也会将更多数据**预读取**进缓存，因此缓存的速度决定了**瞬时速度**（burst），缓存的大小决定了瞬时速度的持续时间，而实际工作中的真实运行速度影响更大
- **并行IO lanes**，多次IO可能会由SSD控制器并行服务

## IO size matters

- **IOPS**限制了单位时间内SSD能够处理的IO请求数量，**throughput**限制了单位时间内SSD能够处理的数据量
- 采用**大量小的数据包**（从而不达到throughput限制）可以测量IOPS
- 采用**少量大的数据包**（从而不达到IOPS限制）可以测量throughput
- 通常没有最优的IO大小，IO取决于应用程序，往往较小的IO可以达到较好的延迟，而较大的IO可以达到较好的带宽利用率

## Write for real

- `O_DIRECT`：操作系统不会缓存
- `O_DSYNC`：磁盘不会缓存
- `FUA`：确保数据写入供电独立的设备

不同的设备对`O_DSYNC`的响应速度不同，确保明智的使用`O_DSYNC`

## Read && Write

- 通常品牌标注的读写性能是纯读取或纯写入的峰值性能，纯IO在实际场合中不多见，而**读写混合的性能表现可能远逊于纯IO**
- 通常SSD对写入的响应好于读取
