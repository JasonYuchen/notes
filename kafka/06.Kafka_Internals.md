# Chapter 06. Kafka Internals

## Cluster Membership

目前Kafka通过Apache ZooKeeper来维护集群信息，每个broker都有一个UID（配置或自动生成），在启动运行时就会将自身注册到ZK上，构造一个**临时节点ephemeral node**，而其他broker、controller、tools等节点就通过**订阅ZK上的`/brokers/ids`路径**来获得broker变化的通知

broker的失联会导致ZK通知所有订阅`/brokers/ids`的节点，但是该UID依然存在于系统中的多个部分，例如partitions的replica list中，若永久失去一个节点时，新节点采用相同的UID启动就会直接加入到集群中（`TODO：是否会有time travel问题？`）

## The Controller

**controller本身也是broker，其特殊性在于负责选举出partition leaders**，默认情况下集群中的第一个broker就会成为controller节点，并且会在ZK中注册一个临时节点为`/controller`，其他brokers后续启动时注册该临时节点失败就会让他们认识到controller已经存在，所有brokers同样会订阅`/controller`路径来获得controller变更的信息

每当认定一个新的controller时，ZK都会赋予一个**单调递增的任期号epoch**，从而所有brokers也会获知该epoch并且**忽略掉epoch小于该值的请求，即zombie fencing避免脑裂split brain**（例如来自于旧controller的过时数据），新的controller会从ZK中读取**副本状态图replica state map**，随后才可以正常控制集群、选举partition leader等

当某个broker离开集群时（宕机或通过发送`ControlledShutdownRequest`有序下线），controller会获得ZK的通知并且找出所有该broker担任partition leader的部分，决定新的leader（通常就是replica list中的下一个broker节点）后再将信息写回到Zookeper，再通知所有相关的replica partitions所在的brokers

### KRaft: Kafka's New Raft-Based Controller

Kafka希望采用自身的**基于Raft共识协议的KRaft组件**来替换原先的ZK依赖，主要动机在于：

- 元数据的更新会同步写入ZK但是异步发送给brokers，而从ZK获得更新也是异步的，这导致了brokers、controllers、ZK所持有的元数据存在一定的**一致性问题**
- 每次controller的重新启动，都必须从ZK读取所有brokers和partitions的元信息，一旦集群规模增加、partitions增多，这一开销成为了主要瓶颈，导致了**controller重启异常缓慢**
- 当前架构下**元数据所有权模糊**，一些元数据更新操作由controller完成、一些操作由broker完成、甚至还有直接在ZK上进行修改的操作
- ZK本身作为分布式系统也需要专业的维护操作，因此**采用Kafka还需要掌握ZK**，带来了额外的开发、运维负担

对于所有用户操作，包括集群修改、增减partition、成员变更等都是一个事件流event stream，**只要能够对这一个事件流达成共识，任意节点在重放replay事件流后就能达到确定的状态，抽象为一个可复制状态机replicated state machine天然适合基于log的Raft共识协议**

KRaft的设计下，**controllers就是一个Raft quorum**管理着元数据的变更，Raft log包含了所有元数据的变更事件，在controllers中会选举出一个**Raft leader作为active controller**执行实际的管理功能，而其余**Raft followers作为follower controllers**持续复制元数据变更日志，并作为热备节点随时可以称为active controller

这些**follower controller一直持有元数据的事件流并且有较新的状态**，被选出作为active controller后几乎不需要花费的时间进行集群状态的读取，并且与原先的brokers被动等待controller推送元数据变更不同，新模式下brokers通过`MetadataFetch`主动向active controller获取最新的元数据更新并带有相应的**最新元数据操作index，即Raft log index**

每个brokers都会持有该元数据index且在每次获取更新时基于index仅获取**增量更新**，并将元数据事件流持久化到本地磁盘，从而**允许读取本地数据加上增量更新以极快的速度完成broker重启**（即使有百万级别的partitions）

集群中所有brokers都会注册在controller quorum中，宕机离线等情况并不会影响注册，在线的brokers若所持有的元数据并非最新状态就会继续通过`MetadataFetch`进行更新，期间会拒绝服务client请求，保证了**只有持有最新元数据状态的节点（active controller、brokers、tools）才能够提供服务**，依赖Raft的**一致性共识解决了上述提到了多节点元数据不一致**问题

更加详细的设计和修改可以参考KIP-500，KIP-595，KIP-631

## Replication

Kafka中的topic会分割成partitions，每个partition都会拥有多个副本replicas存储在不同的brokers上进行容灾，replica分为：

- **Leader replica**
  只有一个leader replica用于接收生产者的写入请求，从而确保一致性，而消费者的读取请求则可以由任意一个replica提供服务，需要特别注意的是leader replica会维护一个**latest committed offset**，只有被这个值包括的消息才可以被读取，来确保一致性，这个值也会由leader replica发送给follower replicas，显然从leader replica上进行读取会略微快于follower replica
- **Follower replica**
  非leader replica都称为follower replica，作为备份存在，所有leader replica的写入都会复制到follower replica上，一旦leader replica所在的broker宕机，follower replica就会被选举成为新的leader replica

**leader replica还需要追踪所有follower replicas持有的消息位置**，follower replicas会发送`Fetch`请求给leader并带上希望获得的消息偏移量（总是有序递增的值），从而leader replica就可以获得follower replica的相应状态：

- **Out-of-sync replicas**
  当一个follower replica持续一段时间（`replica.lag.time.max.ms`）没有尝试`Fetch`来获取最新消息时，就认为该replica已经不再同步，从而当leader出现宕机故障时也不会考虑out-of-sync replicas
- **in-sync replicas**
  相对应的，若一个follower replica持续通过`Fetch`来尝试获得最新的消息，则认为该replica时保持同步的，leader容灾时就会考虑in-sync replicas

另外通常在topic的partitions创建时就会**基于负载均衡的原因**在不同brokers上创建leader replicas，这些起始leader replicas同样也是这些partitions的**preferred leader**，brokers会周期性检查partition的**leader replica是否是preferred leader，若不是且preferred leader属于in-sync replica，则会触发leadership转移**（`auto.leader.rebalance.enable=true`）

### Replicated Logs: Quorums, ISRs, State Machines

补充内容来自[Kafka Doc - Replication](https://kafka.apache.org/documentation/#replication)

**日志复制模型replicated log model**非常适合分布式系统中实现状态机模型，日志就是操作日志，确定性的状态机通过相同的日志可以达到相同的状态，关键就在于对日志达成共识，最简单的方式就是采用**强leader复制协议**，由leader对所有写入进行串行化提交，而**对follower的提交则是一个权衡**，若要求所有follower都提交才认为是leader提交（类似于2PC协议）则延迟受限于最慢的节点，且一旦一个节点宕机会阻塞后续整个写入；若仅要求leader写入就认为提交则一旦leader提交后尚未复制旧宕机，新任leader不持有该数据就出现了数据丢失

通常会要求**写入的副本数与容灾时必须参与选举的副本数存在重叠**，从而确保一定有一个副本拥有最新的数据，这也称为**quorum**，常见的共识算法包括**简单多数投票majority vote**，即`2f+1`个副本可以容忍`f`个副本丢失，每次写入`f+1`个副本才可以提交，例如ZAB，Raft，VR算法，而**Kafka并没有采用简单多数投票，而是采用了与PacificA类似的共识协议**

**majority vote的优缺点较为明显**：其延迟不受限于集群中慢节点的限制，仅需过半节点写入即视为提交，但是其**为了容忍`f`个副本失败需要维护两倍多的`2f+1`个副本**，对存储和网络的压力较大，并且当存活不足`f+1`时整个系统直接陷入不可用；因此majority vote的共识算法大多使用在存储集群元数据等场景

Kafka维护了一个**in-sync replicas, ISR**列表，这些in-sync replicas被要求与leader保持同步、数据足够新从而可以成为下一任leader，而在leader上写入一条数据被视为**提交就是所有ISR都完成写入**（可以通过参数配置），ISR列表通过Zookeeper（新版本中应该是KRaft）进行维护，此时Kafka可以**仅用`f+1`个副本就实现容忍`f`个副本宕机**依然保持服务，从而磁盘和带宽需求显著优于majority vote模式

另一方面Raft等算法要求节点重启后必须携带所有已提交的日志信息，而Kafka没有该约束，分布式系统下节点磁盘同样不可靠，Kafka同样不要求所有ISR写入每一条数据都采用`fsync`强制落盘，**leader或follower replicas宕机重启后可以丢失数据，并且作为follower replica继续从leader replica获取数据**

- 理论上若已提交了数据，即写入所有的ISR，此时全部宕机，则存在丢失数据的可能，但这种场景极端罕见，通常**只要有一个ISR存活就不会发生数据丢失**，假如真的发生了这种事件，实际上应该做的就是停止服务，并执行下述策略的一种：
  - **选择一致性 consistency**：等待至少一个ISR恢复上线并作为leader replica提供服务
  - **选择可用性 availability**：直接采用一个非ISR作为leader replica提供服务并且容忍暂时丢失数据直到ISR上线

注意：[前述](https://github.com/JasonYuchen/notes/blob/master/kafka/03.Kafka_Producers.md#configuring-producers)提到的**producer指定`acks=all`参数实际上是等到所有ISR完成写入**，而不是所有replicas，另外可以通过关闭`unclean leader election`防止非最新数据replica成为leader并指定`minimum ISR size`确保写入至少达到该指定的replica数量来提高消息的可靠性（降低可用性）

## Request Processing

## Physical Storage
