# Chapter 07. Reliable Data Delivery

## Reliability Guarantees

Kafka提供了如下保证：

- **属于同partition的消息有序**，例如若消息B在消息A后由同一个producer写入同一个partition，则Kafka保证消息A的offset在消息B之前，显然consumer也会先消费消息A，再消费到消息B
- 当消息被**写入到所有in-sync replicas ISRs时就可以认为已提交committed**（但不必等待`fsync()`落盘），producer可以自由选择不等待确认、等待leader partition确认或等待ISRs确认
- 只要**至少一个写入的replica存活，则已提交committed的消息不会丢失**
- **consumer只会读取到已提交的消息**

## Replication

replication是Kafka提供可靠性保证的核心机制，具体见[Kafka Internals - Replication](https://github.com/JasonYuchen/notes/blob/master/kafka/06.Kafka_Internals.md#replication)，其中in-sync replica ISR定义为：

- 与ZooKeeper（此后应该是与KRaft）持有一个活跃的session，即在6秒内发送过心跳（时间可配置）
- 从leader replica上持续读取最新消息的，最后一次读取应在10秒内（时间可配置）
- 最近一次读取最新消息的请求能够体现其与leader replica没有任何滞后，即10秒内数据最新（时间可配置）

当一个replica因不满足以上任意一条时，就会被认为out-sync，此时**若一条消息要求写入所有ISRs才算提交，就不再受到这个稍慢导致out-sync节点的影响**，进入out-sync的replica依然会积极获取消息尝试进入in-sync状态，在某些极**端场合下也可能出现out-sync和in-sync反复ping-pong的情况**，需要调整参数稳定集群

## Broker Configuration

- **Replication Factor**, topic-level
  调整`default.replication.factor`可以在broker级别给自动创建的topics确定副本数量，对于设置为N的情况下可以容忍N-1个broker宕机，但是同样引入了写放大，因此该参数的调整往往需要综合考虑：
  - **可用性 Availability**：越多副本，容忍越多brokers宕机，越高可用性
  - **可靠性 Durability**：越多副本，容忍越多磁盘故障导致的永久数据丢失，越高可靠性
  - **吞吐量 Throughput**：越多副本，占用越多带宽用于副本备份，进而影响到集群的吞吐量和延迟
  - **端到端延迟 End-to-end Latency**：越多副本，由于`ack=all`的延迟受ISRs中最慢的节点影响，因此往往越多副本带来的端到端延迟会更高
  - **成本 Cost**：显然越多副本带来的写放大越严重，磁盘空间占用越多，网络带宽占用越多，成本越高

  另外Kafka高度建议**采用rack-awareness的策略来放置不同的replicas，以应对rack级别的失效**（通常**也可以把机架rack认为可用区availability zones或故障域failure domain**）
- **Unclean Leader Election**, broker-level
  若设置`unclean.leader.election.enable=true`，则允许broker宕机时从**out-sync replicas中选举出leader replica**，这意味着已提交消息的丢失，优点是在没有ISRs的时候可以继续提供服务，**即用一致性/可靠性换取可用性**
- **Minimum In-Sync Replicas**，topic/broker-level
  由于采用`ack=all`是认为写入所有ISRs即消息已提交，而从上述可以看出**ISRs的数量是在变动的**，极端情况下可能只有leader是ISR，为了依然保证有多个节点写入数据才算提交，可以通过配置`min.insync.replicas`来强制要求等待至少该数量的ISRs写入才认为提交，在不足这个数量的ISR时producer写入数据就会收到`NotEnoughReplicasException`
- **Keeping Replicas In Sync**，broker-level
  由于in/out-sync状态会极大的影响Kafka诸多功能，并且其状态判定由前述三条规则决定，从而可以通过配置三条规则中的时间约束来调整，包括`zookeeper.session.timeout.ms`、`replica.lag.time.max.ms`
- **Persisting to Disk**
  Kafka并不依赖每个broker主动通过`fsync()`确保数据落盘，而是依赖多个brokers之间replication（这些**replicas被放置在不同的availability zone上，因此极不可能同时出错**）来保证可用性和可靠性，默认情况下Kafka只在创建新segments时主动落盘，其余依赖操作系统页缓存机制的写回磁盘

  Kafka依然提供了配置`flush.messages`和`flush.ms`用于限制处于尚未`fsync()`的最大消息数量或周期性写入磁盘，确保周期性落盘提高可靠性，但是由于落盘的开销较为昂过，这两个配置都有可能极大影响Kafka的吞吐量和延迟

## Using Producers in a Reliable System

## Using Consumers in a Reliable System

## Validating System Reliability
