# Chapter 10. Algorithm Design Techniques

## 1. 贪心算法 Greedy Algorithms

- 概念
    贪心算法就是在**每一步都取当前条件下最优的结果（local optimum）**，在一些情况下，这样运行到最后可能会得到全局最优解（global optimum）也可能是次优解（suboptimal solution）
- **调度问题 A Simple Scheduling Problem**
  - 定义
    参考CPU处理任务，假定有`j1,j2…,jN`个任务需要处理，每个任务耗时`t1,t2…,tN`，在不抢占的情况下，如何安排任务处理顺序以使得**所有任务平均完成时间最小**
  - 最短耗时任务优先
    根据每个任务的耗时，短耗时在前，长耗时在后，可以获得**最优解**
  - 多处理器的情况
    多处理器下依然根据短耗时在前，长耗时在后，排出多个处理队列，也可以获得最优解，但是由于排列顺序，可以获得细节不同的最优解
  - 最短最终完成时间
    在多处理器下虽然根据最短耗时任务优先可以获得平均完成时间最小的最优解，但是从下图可以看出，**最终完成时间（40vs38）是不同的**，而如何达到最短最终完成时间是NP完全问题

    ![10.1](images/10.1.png)

- **哈夫曼编码 Huffman Codes**
  - 定义
    例如ASCII编码是由7bits二进制码构成的，每个ASCII字符都有7bits，但是每个ASCII字符在一段信息中出现的频率并不一致，若只有少数字符出现而依然使用7bits来编码就会出现空间浪费，因为只要更短的编码就足以表现这些少数字符，由此**哈夫曼编码是一种根据出现频率尽可能将高频字符用更短的位来编码，来将整段信息在不引起歧义的情况下压缩**
  - 查找树 Trie
    编码实际上就是从根结点开始找到叶结点的路径，例如下图，叶结点是被编码的字符，则找到`a`的路径`0000`就是`a`的编码，`t`就是`0100`，任何**停留在非叶结点的编码都是二义性的**，例如`001`无法明确是指`i`还是`s`，而整棵查找树在一段信息里的代价就是每个字符的编码长度乘以出现的频率，若`a`的频率远高于`e`，则两者都是4bits的编码是存在优化空间的

    ![10.2](images/10.2.png)

  - 加权路径长度 Weighted Path Length, WPL
    每个叶结点有权重，WPL就是所有叶结点的权重乘以从根结点到叶结点路径长度的总和，哈夫曼树的WPL最小，即**最优二叉查找树，但WPL相同的哈夫曼树可以是多种形态的**
  - **哈夫曼树 Huffman Tree**
    哈夫曼根据每个字符的频率来将高频率的字符安排在接近根的位置，低频率的字符在远离根的位置，来达到最低成本，如下图，显然高频率的`i`和`sp`只需要3bits，低频率的`s`和`nl`需要6bits，同时编码也是**前缀码（prefix code）并且不会引起二义性**，构成哈夫曼树的算法也非常简单，可以如下构建，复杂度是`O(NlogN)`
    1. 初始有一系列已知频率的待编码字符，作为结点，**权重就是频率**（可以采用最小堆存储）
    2. 选取频率最低的两个结点构建哈夫曼树，并将**根结点权重设为两个结点的频率和**
    3. 重复2直到形成一棵树，即哈夫曼树

    ```C++
    HuffmanTree Huffman(MinHeap H)
    {
        int i; 
        HuffmanTree T;
        // 做N-1次合并，每次合并取权重最小的2个结点
        for (i = 1; i < H->Size; i++) {
            T = (HuffmanTree)malloc(sizeof(struct TreeNode));
            T->Left = DeleteMin(H);
            T->Right = DeleteMin(H);
            T->Weight = T->Left->Weight + T->Right->Weight;
            WPL += T->Weight;
            Insert(H, T);
        }
        // 合并N-1次后完成了哈夫曼树，此时Delete返回的即是哈夫曼树的树根
        T = DeleteMin(H);
        return T;
    }
    ```

    注意：**哈夫曼编码是不唯一的，同样WPL值可以是不同构的哈夫曼树**，代码中`T->Left`和`T->Right`可以交换左右子树

- **近似装箱问题 Approximate Bin Packing**
  - 定义
    近似装箱问题将给出装箱问题的**非最优解决但是也有足够好的性能**，这是贪心算法在实践中的很好提现，给定归一化容积为1的箱子和一系列大小在`(0, 1]`的物品`s1,s2…,sN`，要求用**最少的箱子数量来装上这N个物品**
  - **在线装箱问题 Online bin packing**：当前物品未装就不能装后续物品，保证装箱顺序
    无论采用什么算法，**最终在线装箱都至少使用`4/3`倍最优解数量M的箱子**，一些可供参考的算法如下，确保不会使用2倍于最优解数量的箱子（似于内存分配）：
    - 下一个适配（Next Fit）：每次有新物品都**检查上一个物品存放的箱子**是否放的下，若放不下就采用一个新箱子，时间复杂度`O(N)`，最多使用`2M-2`个箱子
    - 第一个适配（First Fit）：每次有新物品都**从头检查每个箱子**，在第一个能放得进的箱子放入，都无法放入才采用一个新箱子，时间复杂度`O(N^2)`（通过二叉树等改进可以使得复杂度在`O(NlogN)`），最多使用`17/10*(M-1)`个箱子
    - 最佳适配（Best Fit）：每次有新物品都**查找一个空余体积大于且相差最小的箱子**，都无法放入才采用一个新箱子，时间复杂度`O(NlogN)`，大约最多使用`1.7M`个箱子
  - 离线装箱问题 Offline bin packing：所有物品已知，不保证装箱顺序
    - 降序第一个适配（First Fit Decreasing）：根据物品尺寸从大到小，并应用第一个适配算法，最多使用`11M/9+6/9`个箱子，并在实践中效果良好，对于随机产生的物品序列期望在`M`外还需要`Θ(√M)`个箱子
    - 降序最佳适配（Best Fit Decreasing）：根据物品尺寸从大到小，并应用最佳适配算法

## 2. 分治法 Divide and Conquer

## 3. 动态规划 Dynamic Programming

## 4. 随机算法 Randomized Algorithms

## 5. 回溯法 Backtracking Algorithms