# Chapter 7. The Practicalities of Persistent State

## 动机 Motivation

### 不可避免的故障 The Inevitability of Failure

通常批处理系统认为输入数据集是有限大小，且可以重新输入的reprocessing the input，因此在持久化快照上的设计相对比较简单（通常**以shuffle作为节点保存快照**，例如MapReduce和Spark的设计均是如此）

而流数据系统的输入数据是无限的且通常认为不能被重新输入一次的，因此流数据系统需要一个更加精细的**持久化快照系统来保证at-least-once/exactly-once语义**（对于at-most-once语义可以不需要快照）

### 正确性与效率 Correctness and Efficiency

由于故障和出错是不可避免的，因此持久化状态可以认为提供了以下两种优势：

- **正确性的基石 A basis for correctness**
  通常流数据处理的无限量数据是不能重复被处理的，采用持久化状态相当于保存了一部分历史数据的处理结果状态，从而在故障恢复时只需要从该状态出发，**相当于已经处理了持久化状态时之前的所有数据**，从而能确保正确性
- **最小化重复工作的方式 A way to minimize work duplicated and data persisted**
  不考虑数据本身是否无限量，处理数据需要耗费资源和时间，而持久化快照相当于暂存了中间结果，从而当面临故障需要重新处理时，可以快速恢复到快照状态而不需要从头处理数据（处理数据需要耗费计算资源，保存未被处理的数据需要耗费存储资源，通常快照占用的空间少于原数据），**最小化重复的工作和最小化存储开销**

## 隐式状态 Implicit State

通常持久化状态需要找到**效率与一致性的平衡点**，总是持久化对一致性有利而对效率不利，总不持久化对效率有利而对一致性不利

### Raw Grouping

将原始数据根据key分组，随后每当有新元素到达时就简单追加到对应组的末尾，如下图：

![7.1](images/7.1.gif)

这种方式相比于增量合并Incremental Combining有以下缺陷：

- **存储更多的数据**，每个窗口的所有输入数据都被持久化存储
- 多次触发器触发导致**重复计算**了已经计算过的元素
- 假如grouping节点就是持久化状态的节点，则宕机重启时就必**须重新计算窗口的结果**

### Incremental Combining

非常多应用在窗口中的聚合函数（例如求和、平均、最大值等）有以下特性：

- 增量聚合过程中展示出**中间状态intermediate form**相比于该状态所需的元素更为紧凑，例如对于`SUM`而言，存储中间状态`10`比存储原始数据`1,2,3,4`更为紧凑
- 增量聚合过程对顺序没有要求，即**满足交换律commutativity和结合律associativity**，例如`COMBINE(COMBINE(a, b), c) == COMBINE(a, COMBINE(c, b))`

从而在聚合时就可以通过以下两个角度进行优化：

- **增量 Incrementalization**
  不需要提前缓存所有数据，而是在抵达窗口后**按抵达顺序直接聚合**即可，这样也可以负载更平滑（相比于需要缓存所有数据并一次性聚合出结果）
- **并行 Parallelization**
  不需要按顺序逐个聚合整个组的所有顺序，可以**分为任意子组进行并行聚合**，最后再合并为最终结果（这也是MapReduce算法的核心思想，充分利用多台分布式机器）

![7.2](images/7.2.gif)

这种方式的主要缺点就是所适用的聚合算法**必须满足交换律和结合律**，而在实践中则需要更加灵活的算法

## 泛化状态 Generalized State

Raw Grouping和Incremental Combining共有的缺点就是**缺乏灵活性**，前者要求分组缓存结果，后者要求满足交换率和结合律，而对于一种泛化通用的持久化状态，通常要求以下三方面的灵活性：

- **数据结构 data structures**
  需要能够支持业务逻辑的高效数据结构，raw grouping实际上使用appendable list，incremental combination实际上使用单个值，实践中往往希望使用更多**复杂但适用的数据结构**例如map、set、graph等
- **读写粒度 r/w granularity**
  对不同的数据结构持久化保存的数据，**任意时刻都能够高效的读取或写入任意量的数据**，读取和写入也应该支持并行和批量化，例如set可以通过bloom过滤器支持高效读取某个元素
- **处理调度 scheduling of processing**
  支持在流数据的**两种时间轴（处理时间、事件时间）上任意时刻发生指定的处理**，类似timer的处理调度，例如指定在某一事件时间上进行触发窗口计算，则在代表该事件时间的数据抵达系统时就会触发窗口计算

### Case Study: Conversion Attribution

raw grouping和incremental combination均不适用于一个常见的流数据处理场合：**广告的转化归因conversion attribution**（用于分析广告转化率有效性的来源）

假定有一个流数据分析引擎处理某个网站的访问数据，且带有导向该网站的impressions，转化归因的目标就是**分析某个impression对达成该网站某种目标（例如注册账户、购买物品等）的有效性**如下图，红色箭头线就代表一个有效的attributed conversion：

![7.3](images/7.3.png)

对于任意的流数据系统，都必须考虑以下要求：

- **乱序数据 Handle out-of-order data**：例如网站的多次点击数据是分布式的，往往会乱序抵达分析引擎
- **大量数据 Handle high volumes of data**：为了尽可能分析用户行为，有可能需要处理并存储大量用户长时间的访问模式（甚至可以是长达90天内的visit-impression-goal tree）
- **反垃圾 Protect against spam**：广告转化率直接影响到广告投放和收益，因此分析引擎的正确性必须得到保证，从而必须满足恰好一次以及反垃圾（例如某个用户在短时间内多次点击同一个广告不应该产生多次有效数据）
- **优化性能 Optimize for performance**：考虑到读写持久化存储代价高，分析引擎往往需要处理相当大规模的数据，因此每个环节都必须考虑性能

### Conversion Attribution with Apache Beam
