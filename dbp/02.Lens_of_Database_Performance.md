# Chapter 02 Your Project, Through the Lens of Database Performance

## Workload Mix (R/W Ratio)

- **Write-Heavy Workloads**

    choose database that stores data in immutable files (**LSM trees**), be prepared for **higher storage requirements** and **slower reads**

    read amplification can be mitigated by database's caching subsystem

    **Write-heavy workloads are typically more costly** (~5x) than read-heavy workloads in some vendor's pricing models, e.g. DynamoDB, Bigtable

- **Read-Heavy Workload**

    choose database that uses **B-tree**, but the advantage that read-optimized database offer for reads is generally **not as significant as the advantage that write-optimized databases offer for writes**.

    - what is the **nature of the data** that will be querying mostly frequently? access pattern
    - does it tolerate potentially **stale reads**? consistency guarantee
    - **how frequently** is it accessed? hot data
    - does it require aggregations, joins, or **querying flexibility on non-primary-key** fields?
    - what is the level of **cardinality**?

- **Mixed Workloads**

    are reads from cold data or hot data?
    - tiered storage
    - hot data cache
    - **cache miss rate** to determine the access pattern

    write-optimized databases can improve read latency via internal caching

- **Delete-Heavy Workloads**

    e.g. using database as a durable queue, not suitable for LSM-tree databases which stores data in **immutable files and use tombstones** to mark data that are slated for deletion

    deletes on append-only databases result in tombstone writes, leading to read amplification and elevate the read latencies, be sure to **combine the delete-heavy pattern with a compaction strategy tailored for efficient data eviction**

    One successful example from [Real-Time Event-Driven Analytics System](https://www.scylladb.com/2023/05/15/tencent-games-real-time-event-driven-analytics-systembuilt-with-scylladb-pulsar/):
    - study of how deletes are performed
    - careful data modeling
    - avoid reads that potentially scan through a large set of deleted data
    - tune compaction strategy (e.g. **time window compaction strategy** to aggressively expire tombstones)

- **Competing Workloads (Real-Time vs Batch)**

    OLTP characteristics:
    - Many transactions
    - Latency sensitive
    - Small payloads
    - Balanced read/write or Heavy write

    OLAP characteristics:
    - Few transactions
    - Throughput sensitive
    - Large (return) payloads
    - Heavy read, including full table scans

    the database must strictly **prioritize which activities** get what specific share of resources under contention:
    - physical isolation
    - logical isolation
    - scheduled isolation

## Item Size

higher payloads require more processing, I/O and network traffic than smaller payloads

- **page cache** (4KB by default), serve several pages for a large payload, which means larger payloads deplete the cache space more frequently
- **networking**, set realistic latency and throughput expectations, e.g. it is unlikely to serve 200KB payloads with single-digit millisecond latencies.
- **do not store large blobs**, only store metadata of such blobs, and store data in cold storage, e.g. AWS S3, Azure blob, GCP
- **memory fragmentation**, smaller payloads may reduce memory efficiency

## Item Type

- **compression-friendly item type** to improve storage utilization
- use databases that are **optimized for your certain item type**, e.g. MongoDB for frequently process JSON data
- choose the data type that's **the minimum needed** to store the type of data you need, do not pay for what you do not use
- **use collections (sets, lists, maps) judiciously**, collections are meant to store a small amount of information, e.g. several phone numbers of an individual home
- **use User-Defined Types, UDTs judiciously**, UDTs will typically give [performance boost](https://www.scylladb.com/2017/12/07/performance-udt/) when deserialize several values as a single column (*will have other limitations**)

## Dataset Size

**Factoring in your growth** is critical for avoiding unpleasant surprises in production, from an operational as well as a budget perspective

## Throughput Expectations

- **separate read throughput vs. write throughput**

    database's read path is usually quite distinct from its write path

- **apply little's raw**
- same database's past or current throughput with one use case is **no guarantee of future results with another**
- **plan for the likely peaks** and reserve boosting for atypical situations
- scaling a cluster boosts the capacity, but be careful for **hot partition** problem

## Latency Expectations

**Latency is a more complex challenge than throughput**: You can increase throughput by adding more nodes, but there’s no simple solution for reducing latency

- sometimes monitoring systems are configured to omit **outliers**, e.g. 0-1000ms is going to overlook >1000ms
- the measurement starts with the client sending the request and ends with the client receiving the response
    - network time
    - client-side processing
    - database processing
  - **need observability in both the database and the client-side**

## Concurrency

- **concurrency must be judiciously balanced based on the little's law** to reach appropriate throughput and latency values
- past the maximum throughput, increasing concurrency will increase latency
- ***[Performance Under Load](https://netflixtechblog.medium.com/performance-under-load-3e6fa9a60581)***

## Connected Technologies

don’t overlook the performance gains you can achieve by **reviewing and tuning its connected components**

use **benchmarking** to determine the severity of the impact from a performance perspective

## Demand Fluctuations

- **predictable fluctuations**, e.g. food delivery, black friday

    scale up the cluster ahead of the anticipated spike, or provision an infrastructure that supports the peak traffic

- **unpredictable fluctuations**, e.g. emergency services, news

    control the concurrency on the client side so that it doesn't overwhelm the database, or scale out the clusters as fast as possible

**Autoscaling** is best when:

- load changes have high amplitude
- the rate of change is in the **magnitude of hours**, e.g. [2.5 hours from 0 to 40k rps](https://theburningmonk.com/2019/03/understanding-the-scaling-behaviour-of-dynamodb-ondemand-tables/)
- the load peak is **narrow** relative to the baseline, e.g. [DynamoDB autoscaling](http://www.scylladb.com/2021/07/08/dynamodb-autoscaling-dissected-when-a-calculator-beats-a-robot/)

## ACID Transactions

- **ACID-compliant use cases**
    - pay special attention to the **master nodes / primary query coordinators**
    - try to ensure the majority of transactions are **isolated to the minimum amount of resources**
    - consider to **rethink the data model** and reimplement it without the need of ACID, e.g. [how to implement financial transaction with lightweight transaction](https://www.scylladb.com/2020/07/15/getting-the-most-out-of-lightweight-transactions-in-scylla/)
- **Non-ACID-compliant use cases**
    - some databases support **light weight transactions** that allow "atomic compare and set"
    - use cases relying heavily on ACID will require much more infrastructure power, e.g. [how DynamoDB transaction works](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html)

## Consistency Expectations

*how much risk **your application can tolerate** with respect to inconsistency*

**tunable consistency** will help you achieve a balance between strong consistency and performance

## Geographic Distribution

- Consider the **increased load** that your target region or regions will receive in the event of a full region outage
- **Not only the database systems** but also the application, web servers, messaging queue systems, and so on, are geographically replicated
- Very **good network links** are required for geo-replicated databases

## High-Availability Expectations

*understand what **your application can tolerate** if a node goes down*

**replication and consistency both come at a cost** to performance, don’t opt for more than your business really needs.
