# Chapter 09. Virtual Memory

## 1. 背景 Background

## 2. 按需换页 Demand Paging

程序运行时只有部分进入内存，其他**页只有在需要时才从外存中调入**，并且不像交换需要传输整个进程而只需要运输部分所需的页进入内存

- **执行流程**
  当进程试图访问不在内存中的页，即访问标记为无效的页时，可能是非法访问也可能是页在外存中，此时产生**页错误中断page fault**，通过中断处理程序：
  1. 检查进程的内部页表（通常与PCB一起保存）来确定是否是非法访问
  2. 若是非法访问，则终止进程；若是合法访问，则应将页调入内存
  3. 找到一个空闲物理帧
  4. 调度磁盘IO将页读入刚分配的物理帧
  5. 完成后修改进程PCB和页表，表示页在内存中
  6. **重新执行**导致page fault的指令，现在应该能正常访问
- 按需调页的性能
  有效访问时间effective access time

## 3. 写时复制 Copy-on-Write

每次`fork()`创建新进程时子进程和父进程拥有完全一样的页，为了避免额外的开销，使子进程和父进程**共享（而不是复制）并标记这些页为写时复制页**，当子进程对页进行写时才为子进程复制具体的页，称为写时复制，同时往往操作系统会维护一个空闲缓冲池，当子进程**需要复制页时从池中获取空闲页**并按需填零zero-fill-on-demand以清除之前的内容

注意：与`fork()`相应的还有`vfork()`，后者用于在子进程创建后挂起父进程，并且不再写时复制，**子进程所有修改在父进程重新运行后都是可见的**，因此vfork()效率更高但是需要谨慎使用

## 4. 页替换 Page Replacement

- **基本页置换原理**
  若空闲帧用完，则需要进行页置换，**查找当前没有使用的帧**（页置换算法），将其内容写到交换空间并修改页表等信息以表示该页不在内存中，随后作为空闲帧提供给所要调入的页，此时页错误处理程序需要增加处理页置换的部分，可以通过**修改位/脏位**（modify bit/dirty bit）来标记页从外存进入内存后是否修改过，若修改过则在置换时需要写回外存，若无修改则简单丢弃即可降低开销
- **先进先出页置换 FIFO Page Replacement**
  每次都置换最先调入内存的帧，FIFO算法可能导致**出现[Belady异常](https://en.wikipedia.org/wiki/B%C3%A9l%C3%A1dy%27s_anomaly)**，即更多的帧数反而会提高缺页率

  ```text
  3 frames
  Requests: 3 2 1 0 3 2 4 3 2 1 0 4 => 9 page faults
    Newest: 3 2 1 0 3 2 4 4 4 1 0 0
   Evicted: - - - 3 2 1 0 - - 3 2 - => 6 evicted

  4 frames
  Requests: 3 2 1 0 3 2 4 3 2 1 0 4 => 10 page faults
    Newest: 3 2 1 0 0 0 4 3 2 1 0 4
   Evicted: - - - - - - 3 2 1 0 3 2 => 6 evicted
  ```

- **最优置换 Optimal Page Replacement**
  每次都置换**将来最长时间不使用**的帧，不会有Belady异常且缺页率最低，但**无法实现**（需要预知），又称为栈算法
- **最近最少使用页置换 LRU Page Replacement**
  对最优置换的近似，每次都**置换过去最长时间没有使用的帧**，不会有Belady异常，往往需要额外的硬件支持，例如为每个页表项关联一个计数器或是维护一个栈来存放每次使用的页，当引用一个页时就将其从栈中删除并添加到栈顶，置换时就置换处于栈底的页，LRU也被称为栈算法
- **近似LRU页置换 LRU-Approximation Page Replacement**
  - 附加引用位算法 Additional-Reference-Bits Algorithm：基于LRU，每隔一段时间**递减计数器**，计数器清零就被置换
  - 二次机会算法 Second-Chance Algorithm：基于FIFO，由**引用位给予本应被置换的页二次机会**
  - 增强型二次机会算法 Enhanced Second-Chance Algorithm：基于FIFO，**引用位+修改位**
- **基于计数的页置换 Counting-Based Page Replacement**
  - 最不经常使用页置换 Least Frequently Used，LFU
  - 最常使用页置换 Most Frequently Used，MFU
- **页缓冲算法 Page-Buffering Algorithms**
  空闲帧池并不等到要提供空闲帧时才将内容写出到外存，而是**根据标志位定时写出**，这样当需要空闲帧时可以立即提供不需要等待写出，同时当发生缺页异常时先到空闲帧池寻找是否存在所需页，以此来缓冲页置换并提高效率

部分特殊的应用程序比操作系统更清楚自己对内存的需求，因此针对通用程序的操作系统提供的页置换反而可能会劣化性能，因此操作系统允许特殊程序绕过所有文件服务，**直接操作磁盘（raw disk）并进行I/O（raw I/O）**

## 5. 帧分配 Allocation of Frames

- 最小帧数 Minimum Number of Frames
  分配的最小帧数由系统架构决定，分配的最大帧数由可用帧数决定
- **分配算法 Allocation Algorithms**
  - 平均分配 equal allocation：每个进程获得相等的帧数
  - 比例分配 proportional allocation：根据每个进程拥有的虚拟内存大小或是优先级按比例分配帧数
- 全局分配和局部分配 Global vs. Local Allocation
  - **全局分配 global replacement**：页面置换时，候选页是所有页构成的集合，即**可以替换别的进程的页**来调入本进程的页
  - **局部分配 local replacement**：页面置换时，只能置换自己拥有页的集合中的页，即**只能替换本进程的页**
- **非统一内存访问 Non-Uniform Memory Access, NUMA**
  在一些复杂多CPU多内存系统上，一些CPU可能访问**某部分内存延迟更低**，取决于系统架构，这种非均匀内存访问要求帧分配离对应CPU越近越好，即延迟越低越好

## 6. 系统抖动 Thrashing

物理帧不够时，若系统替换了某些随后马上被需要的页，进入**不断出现page fault交替替换页**的行为，称为**系统抖动**，一个进程若处理换页的时间多于实际执行的时间，则称这个进程在抖动

- **抖动原因 Cause of Thrashing**
- **工作集模型 Working-Set Model**
  基于**局部性假设**，使用工作集合窗口来记录最近多个页的引用，当一个页在使用中则其在工作集内，当经过一段时间未引用则从工作集中删除，操作系统可以**根据动态变化的工作集来动态分配给进程帧数**，尽可能防止但不彻底避免抖动并提高了性能
- **页错误频率 Page-Fault Frequency**
  根据页错误频率可以反映帧数的不足程度，因此直接控制页错误频率来防止抖动，当**页错误频率上升时就分配更多的帧数**
- 总结 Concluding Remarks
  **提升总的物理帧数**，最好保证所有进程的工作集都在物理内存中是最好的解决方案

## 7. 内存映射文件 Memory-Mapped Files

使用**虚拟内存技术将文件I/O作为普通内存**访问，称为文件的内存映射memory mapping

## 8. 内核内存分配 Allocating Kernel Memory

用户态进程需要额外内存时从内核维护的**空闲页帧池**中获取页，池由页替换算法维护；而**内核内存分配是从空闲内存池中获取**而非空闲页帧池，内核代码与数据往往不受分页系统控制

- **Buddy系统 Buddy System**
  从物理上**连续大小固定的段**上进行分配，按**2的幂次大小**进行分配，因此可以通过合并而快速形成更大的段，但是由于要调整到2的幂次因此可能会产生**大量内部碎片**

  例如现在有512KB的一段空闲内存，此时需要100KB，就会分配128KB，分割成256KB，128KB，128KB，并将其中128KB分配给程序，此时产生28KB的内部碎片，当归还时就会与空闲的128KB合并成258KB，再进一步与256KB合并成512KB
- **Slab分配 Slab Allocation**
  Slab由一个或多个**连续物理页**构成，内核有内存池称为**高速缓存cache**，含有一个或多个Slab，每个**内核数据结构都有对应的一个高速缓存**，每个高速缓存内有所对应内核数据结构的对象实例（类似对象池）
  - 创建cache时包含若干标记为空闲的对象，需要内核数据结构对象时就从cache中获取并标记使用
  - Slab分配器首先从部分空闲的Slab开始分配，若没有就从空的Slab分配，若还是没有就从物理连续页上分配新的Slab并赋值给新的cache，然后再分配给对象
  - 没有因碎片造成浪费，每个内核数据结构对应相应的cache，每个cache有若干Slab，每个Slab分为若干与对象大小相同的内存块，因此需要分配对象时Slab分配器返回的内存刚好可以放下对象
  - 另外由于对象预先创建并从cache上快速分配，用完只需标记空闲就可下次再使用，效率很高

## 9. 其他考虑 Other Considerations

- **预分页 Prepaging**
  进程重新启动时，往往有较高的缺页错误直到所要用的页基本都被调入内存为止，可以通过维护进程被交换到外存之前的工作集，在重启时一次性调入工作集中的所有页，来避免重启时较高的缺页率
- 页大小 Page Size
  **大页（BigPage/LargePage/HugePage）**
- TLB范围 TLB Reach
- 反向页表 Inverted Page Tables
- 程序结构 Program Structure
  由于页表及页置换算法往往基于局部性原理，而这对程序而言是透明的，**写程序时注重局部性原理**往往能对程序性能有所提升
- **I/O互锁和锁页**
  当程序在等待I/O完成时往往被CPU挂起，此时**需要确保与I/O有关的页被锁在物理帧**中，否则I/O影响到的页可能已经被页置换算法到其他进程的页中
